{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Componente como Servi√ßo\n",
    "\n",
    "## Passo 2 - Componente a partir do Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iplantuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output for /home/santanche/git/component2learn/notebooks/ai/8e4ff04a-654c-4c8a-a64a-604e6c4caf81.uml to 8e4ff04a-654c-4c8a-a64a-604e6c4caf81.svg\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" contentStyleType=\"text/css\" height=\"101px\" preserveAspectRatio=\"none\" style=\"width:393px;height:101px;background:#FFFFFF;\" version=\"1.1\" viewBox=\"0 0 393 101\" width=\"393px\" zoomAndPan=\"magnify\"><defs/><g><!--class Predictor--><g id=\"elem_Predictor\"><rect codeLine=\"1\" fill=\"#F1F1F1\" height=\"80.5938\" id=\"Predictor\" rx=\"2.5\" ry=\"2.5\" style=\"stroke:#181818;stroke-width:0.5;\" width=\"372.3633\" x=\"7\" y=\"7\"/><ellipse cx=\"157.3838\" cy=\"23\" fill=\"#B4A7E5\" rx=\"11\" ry=\"11\" style=\"stroke:#181818;stroke-width:1.0;\"/><path d=\"M153.3057,18.7656 L153.3057,16.6094 L160.6963,16.6094 L160.6963,18.7656 L158.2275,18.7656 L158.2275,26.8438 L160.6963,26.8438 L160.6963,29 L153.3057,29 L153.3057,26.8438 L155.7744,26.8438 L155.7744,18.7656 L153.3057,18.7656 Z \" fill=\"#000000\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"14\" font-style=\"italic\" lengthAdjust=\"spacing\" textLength=\"63.0957\" x=\"177.8838\" y=\"27.8467\">Predictor</text><line style=\"stroke:#181818;stroke-width:0.5;\" x1=\"8\" x2=\"378.3633\" y1=\"39\" y2=\"39\"/><line style=\"stroke:#181818;stroke-width:0.5;\" x1=\"8\" x2=\"378.3633\" y1=\"47\" y2=\"47\"/><ellipse cx=\"18\" cy=\"60.6484\" fill=\"#84BE84\" rx=\"3\" ry=\"3\" style=\"stroke:#038048;stroke-width:1.0;\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"14\" lengthAdjust=\"spacing\" textLength=\"183.292\" x=\"27\" y=\"63.9951\">train(csv_file_path: string)</text><ellipse cx=\"18\" cy=\"76.9453\" fill=\"#84BE84\" rx=\"3\" ry=\"3\" style=\"stroke:#038048;stroke-width:1.0;\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"14\" lengthAdjust=\"spacing\" textLength=\"346.3633\" x=\"27\" y=\"80.292\">predict(age: int, gender: int, ethnicity: int): string</text></g><!--SRC=[DSlD2S0W343XkrFagBGJE4Kt4D6eWP9A38LIkdkXFySFtYDMb18JmYAOAUacS1g02LGYiKrZ3uLM33rgyp1KYAjxWluEDbRqGAmpLEICyW6rCINIux7xNtFT]--></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%plantuml\n",
    "\n",
    "@startuml\n",
    "\n",
    "interface Predictor {\n",
    "  + train(csv_file_path: string)\n",
    "  + predict(age: int, gender: int, ethnicity: int): string\n",
    "}\n",
    "\n",
    "@enduml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output for /home/santanche/git/component2learn/notebooks/ai/74041eb9-e92c-43c1-8767-230c8af8b87e.uml to 74041eb9-e92c-43c1-8767-230c8af8b87e.svg\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" contentStyleType=\"text/css\" height=\"68px\" preserveAspectRatio=\"none\" style=\"width:227px;height:68px;background:#FFFFFF;\" version=\"1.1\" viewBox=\"0 0 227 68\" width=\"227px\" zoomAndPan=\"magnify\"><defs/><g><!--entity FoodPredictor--><g id=\"elem_FoodPredictor\"><rect fill=\"#F1F1F1\" height=\"46.2969\" rx=\"2.5\" ry=\"2.5\" style=\"stroke:#181818;stroke-width:0.5;\" width=\"137.166\" x=\"7\" y=\"7\"/><rect fill=\"#F1F1F1\" height=\"10\" style=\"stroke:#181818;stroke-width:0.5;\" width=\"15\" x=\"124.166\" y=\"12\"/><rect fill=\"#F1F1F1\" height=\"2\" style=\"stroke:#181818;stroke-width:0.5;\" width=\"4\" x=\"122.166\" y=\"14\"/><rect fill=\"#F1F1F1\" height=\"2\" style=\"stroke:#181818;stroke-width:0.5;\" width=\"4\" x=\"122.166\" y=\"18\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"14\" lengthAdjust=\"spacing\" textLength=\"97.166\" x=\"22\" y=\"39.9951\">FoodPredictor</text></g><!--entity Predictor--><g id=\"elem_Predictor\"><ellipse cx=\"188.58\" cy=\"30.15\" fill=\"#F1F1F1\" rx=\"8\" ry=\"8\" style=\"stroke:#181818;stroke-width:0.5;\"/><text fill=\"#000000\" font-family=\"sans-serif\" font-size=\"14\" lengthAdjust=\"spacing\" textLength=\"63.0957\" x=\"157.0321\" y=\"60.1451\">Predictor</text></g><!--link FoodPredictor to Predictor--><g id=\"link_FoodPredictor_Predictor\"><path d=\"M144.44,30.15 C156.05,30.15 167.66,30.15 179.27,30.15 \" fill=\"none\" id=\"FoodPredictor-Predictor\" style=\"stroke:#181818;stroke-width:1.0;\"/></g><!--SRC=[YtRBpqy9A4fDoKmkoI-ALT1LW7C0]--></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%plantuml\n",
    "\n",
    "@startuml\n",
    "\n",
    "[FoodPredictor] - Predictor\n",
    "\n",
    "@enduml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class FoodPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression()\n",
    "        self.le_gender = LabelEncoder()\n",
    "        self.le_ethnicity = LabelEncoder()\n",
    "        self.le_fcid = LabelEncoder()\n",
    "\n",
    "    def train(self, csv_file_path):\n",
    "        # Load the data\n",
    "        data = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Encode categorical variables\n",
    "        data['gender'] = self.le_gender.fit_transform(data['gender'])\n",
    "        data['ethnicity'] = self.le_ethnicity.fit_transform(data['ethnicity'])\n",
    "        data['fcid_code'] = self.le_fcid.fit_transform(data['fcid_code'])\n",
    "\n",
    "        # Split features and target\n",
    "        X = data[['age', 'gender', 'ethnicity']]\n",
    "        y = data['fcid_code']\n",
    "\n",
    "        # Split data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Model accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    def predict(self, age, gender, ethnicity):\n",
    "        # Encode input data\n",
    "        gender_encoded = self.le_gender.transform([gender])[0]\n",
    "        ethnicity_encoded = self.le_ethnicity.transform([ethnicity])[0]\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = self.model.predict([[age, gender_encoded, ethnicity_encoded]])\n",
    "\n",
    "        # Decode prediction\n",
    "        fcid_code = self.le_fcid.inverse_transform(prediction)[0]\n",
    "\n",
    "        return fcid_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.61\n",
      "For a person with age 31, gender code 1, and ethnicity code 2:\n",
      "The predicted FCID code is: 603182000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santanche/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/santanche/.local/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the predictor\n",
    "predictor = FoodPredictor()\n",
    "\n",
    "# Train the model\n",
    "# Note: Make sure the file \"intake-person-demo(beans).csv\" is in the correct directory\n",
    "predictor.train(\"intake-person-demo(beans).csv\")\n",
    "\n",
    "# Now, let's make a prediction with the given parameters\n",
    "age = 31\n",
    "gender = 1  # Assuming 1 represents a specific gender in your encoding\n",
    "ethnicity = 2  # Assuming 2 represents a specific ethnicity in your encoding\n",
    "\n",
    "# Make the prediction\n",
    "predicted_fcid = predictor.predict(age, gender, ethnicity)\n",
    "\n",
    "# Print the result\n",
    "print(f\"For a person with age {age}, gender code {gender}, and ethnicity code {ethnicity}:\")\n",
    "print(f\"The predicted FCID code is: {predicted_fcid}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
